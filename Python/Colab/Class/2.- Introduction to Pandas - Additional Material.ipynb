{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction to Pandas - Additional Material.ipynb","provenance":[{"file_id":"11CNisUtxLvRlcoCQ4RjZgr0veSJLvOQZ","timestamp":1611067529059},{"file_id":"1rEptPe8kxPmQwHQy0NDFgwg7Wn0PDLYt","timestamp":1607928991708}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"68USG-y8H6Wy"},"source":["# Additional practice\n","\n","Use this notebook to read through and execute cells, testing what you've learnt in class with the other notebook and experimenting yourself with the data in the imported dataframes.\n","\n","## Initial set up"]},{"cell_type":"markdown","metadata":{"id":"Rh63pnDfIAyU"},"source":["Import relevant libraries:"]},{"cell_type":"code","metadata":{"id":"8rfEBM8l_gUJ"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqyQfghcIE50"},"source":["Mount Drive content:"]},{"cell_type":"code","metadata":{"id":"SEW-wFWK7QJX"},"source":["drive_loc = '/content/gdrive'\n","files_loc = os.path.join(drive_loc, 'MyDrive', 'pdsfiles')\n","\n","from google.colab import drive\n","drive.mount(drive_loc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qh-TpWoSqQ4L"},"source":["!mkdir -p {files_loc}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fk1x78LBNkiA"},"source":["# Using `iloc` and `loc` to select rows and columns in Pandas DataFrames\n","\n","Remember, `ix` is deprecated as of Pandas 0.20, so we'll be using `loc` and `iloc`."]},{"cell_type":"code","metadata":{"id":"rURCUF69Ofx_"},"source":["!wget https://bit.ly/ks-pds-csv4 -O {files_loc}/uk_data.csv\n","contents = !ls {files_loc}/*uk_data*\n","uk_data_file = contents[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFBNUYNaOFZy"},"source":["# read the data from a CSV file.\n","data = pd.read_csv(uk_data_file)\n","# set a numeric id for use as an index for examples.\n","data['id'] = [random.randint(0,1000) for x in range(data.shape[0])]\n"," \n","data.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WP0Wew1HPy2W"},"source":["data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxuceXFkqtaO"},"source":["## Using `iloc`\n","\n","Let's do single selections using iloc for dataframes, starting with the rows.\n","\n","This selects the first row of the data frame (note the Series data type output):"]},{"cell_type":"code","metadata":{"id":"il9PNIygqd3H"},"source":["data.iloc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8F-4FMa5rDcs"},"source":["Let's now select the second row of the data frame:"]},{"cell_type":"code","metadata":{"id":"E9XIfJ-nqooG"},"source":["data.iloc[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOTrofDArJcQ"},"source":["We can do the last row as well, using the familiar Python syntax for it:"]},{"cell_type":"code","metadata":{"id":"AIwilpccqp0r"},"source":["data.iloc[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dz9WtOFYrQin"},"source":["Let's do the same by columns:"]},{"cell_type":"code","metadata":{"id":"Qf2P8Tg1qq1e"},"source":["data.iloc[:,0] # first column of data frame (first_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2hy5oSWqr-c"},"source":["data.iloc[:,1] # second column of data frame (last_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKikYnfMqso8"},"source":["data.iloc[:,-1] # last column of data frame (id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fxxFmjtrjjN"},"source":["Multiple columns and rows can be selected together using the .iloc indexer and Python slices syntax:"]},{"cell_type":"code","metadata":{"id":"PAeJ1SDCrm8a"},"source":["data.iloc[0:5] # first five rows of dataframe"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Tq3Vx06r2Am"},"source":["data.iloc[:, 0:2] # first two columns of data frame with all rows"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3Um0IOhr6aa"},"source":["data.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s6lOENyCr_an"},"source":["data.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of data frame (county -> phone1)."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1Me4l4gsGwg"},"source":["There’s two thing to consider when using iloc like this:\n","\n","- `.iloc` returns:\n","  - a Pandas Series when one row is selected\n","  - a Pandas DataFrame when multiple rows are selected, or if any column in full is selected.\n","  \n","  If you require DataFrame output, pass a single-valued list.\n","\n","  When using `.loc`, or `.iloc`, you can then control the output format by passing *lists* or *single values* to the selectors.\n","\n","- When selecting multiple columns or multiple rows in this manner, remember that your selection will go from the first number to one minus the second number, as it is usual with Python.\n","\n","In practice, it is better to use `.loc`.\n"]},{"cell_type":"markdown","metadata":{"id":"hXX5Iujktzyl"},"source":["## Using `loc`\n","\n","The Pandas `loc` indexer can be used with DataFrames for two different use cases:\n","\n","1. Selecting rows by label/index\n","2. Selecting rows with a boolean/conditional lookup\n","\n","The `loc` indexer is used with the same syntax as iloc: `data.loc[<row selection>, <column selection>]`.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HQGKF6IUubYz"},"source":["### Label-based / Index-based indexing using `loc`\n","\n","Selections using the loc method are based on the index of the data frame (if defined). Where the index is set on a DataFrame, using `df.set_index()`, the `.loc` method directly selects based on index values of any rows.\n","\n","For example, setting the index of our test data frame to the persons \"last_name\":"]},{"cell_type":"code","metadata":{"id":"N2JA2wvDutSZ"},"source":["data.set_index('last_name', inplace=True)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrgLzbNgu-Cj"},"source":["Now with this new index, we can directly select rows for different \"last_name\" values using `.loc[<label>]`. For example:"]},{"cell_type":"code","metadata":{"id":"IDaNZ-MNvN5T"},"source":["data.loc['Andrade']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkbu4B5nvTGx"},"source":["data.loc[['Andrade','Veness']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EkjwSM7vhwi"},"source":["Note that the first example returns a series, and the second returns a DataFrame. You can achieve a single-column DataFrame by passing a single-element list to the `.loc` operation.\n","\n","Select columns with `.loc` using the names of the columns. In most of the data work, typically thera are named columns, so use these named selections."]},{"cell_type":"code","metadata":{"id":"Pc8oVRfPyBVz"},"source":["data.loc[['Andrade','Veness'], ['first_name','address', 'city']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TclpoFNByYki"},"source":["You can select ranges of index labels – the selection `data.loc['Bruch':'Julio']`will return all rows in the data frame between the index entries for “Bruch” and “Julio”.\n","\n","The following examples should now make sense:"]},{"cell_type":"code","metadata":{"id":"a1rcN5xLyg9I"},"source":["# Select rows with index values 'Andrade' and 'Veness', with all columns between 'city' and 'email'\n","data.loc[['Andrade', 'Veness'], 'city':'email']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSUZhpMCyk5v"},"source":["# Select same rows, with just 'first_name', 'address' and 'city' columns\n","data.loc['Andrade':'Veness', ['first_name', 'address', 'city']]\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3fAM8kH1mAy"},"source":["Now, we reset the index before selecting the old index. If not, we may end up with a multiple index, a situation we don't want to deal with as of now:"]},{"cell_type":"code","metadata":{"id":"-wkuTjKf0Gl4"},"source":["data.reset_index(inplace=True)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzsLY_-t1iS-"},"source":["data.set_index('id', inplace=True)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUevU3PNymwI"},"source":["# select the row with 'id' = 487\n","data.loc[487]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HivMt4BmdI9h"},"source":["Note that in the last example, `data.loc[487]` (the row with index value 487) **is not equal** to `data.iloc[487]` (the 487th row in the data). The index of the DataFrame can be out of numeric order, and/or a string or multi-value.\n","\n","Remember that you can also recover the row in a DataFrame format if you specify a list instead of the raw element:"]},{"cell_type":"code","metadata":{"id":"pefTzyxTr-5E"},"source":["data.loc[[487]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"st_UuAZZp8-r"},"source":["### Boolean indexing\n","\n","Conditional selections with boolean arrays using `data.loc[<selection>]` is a common method to use with Pandas DataFrames. With boolean indexing or logical selection, you pass an array or Series of True/False values to the `.loc` indexer to select the rows where your Series has True values.\n","\n","In most use cases, you will make selections based on the values of different columns in your data set.\n","\n","For example, the statement `data['first_name'] == 'Antonio'` produces a Pandas Series with a True/False value for every row in the `data` DataFrame, where there are `True` values for the rows where the first_name is 'Antonio'. These type of boolean arrays can be passed directly to the `.loc` indexer as so:"]},{"cell_type":"code","metadata":{"id":"pq1tELBUqkCM"},"source":["data.loc[data['first_name'] == 'Antonio']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZ372giLs_ib"},"source":["As before, a second argument can be passed to .loc to select particular columns out of the data frame.\n","\n","Again, columns are referred to by name for the loc indexer and can be a single string, a list of columns, or a slice “:” operation:"]},{"cell_type":"code","metadata":{"id":"JEGiKmQKtD_X"},"source":["data.loc[data['first_name'] == 'Erasmo', ['company_name', 'email', 'phone1']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ukqGoomtaVr"},"source":["You can see that when selecting columns, if one column only is selected, the `.loc` operator returns a Series. For a single column DataFrame, use a one-element list to keep the DataFrame format, for example:\n"]},{"cell_type":"code","metadata":{"id":"EW8lxjGItg3g"},"source":["data.loc[data['first_name'] == 'Antonio', 'email']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5kNjfjytwKr"},"source":["data.loc[data['first_name'] == 'Antonio', ['email']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o-pVD_y1t6I8"},"source":["Selecting rows with first name Antonio and all columns between 'city' and 'email:"]},{"cell_type":"code","metadata":{"id":"6eZjE9hXt-TM"},"source":["data.loc[data['first_name'] == 'Antonio', 'city':'email']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3C2UI0Jat8mJ"},"source":["Select rows where the email column ends with 'hotmail.com', include all columns:"]},{"cell_type":"code","metadata":{"id":"-TlQOF6SuKfX"},"source":["data.loc[data['email'].str.endswith(\"hotmail.com\")]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9yq0r78LuFYx"},"source":["Select rows with last_name equal to some values, all columns:"]},{"cell_type":"code","metadata":{"id":"o14h80rRuQR5"},"source":["data.loc[data['first_name'].isin(['France', 'Tyisha', 'Eric'])]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVTbOuEHuGFw"},"source":["Select rows with first name 'Antonio' **AND** hotmail email addresses:"]},{"cell_type":"code","metadata":{"id":"KnstgVMbuZNh"},"source":["data.loc[data['email'].str.endswith(\"gmail.com\") & (data['first_name'] == 'Antonio')] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkR6QEsHuGpR"},"source":["Select rows with id column between 100 and 200, and just return 'postal' and 'web' columns. But let's first reset the index so `id` is a column:"]},{"cell_type":"code","metadata":{"id":"uNWTs1gaujU1"},"source":["data.reset_index(inplace=True)\n","data.loc[(data['id'] > 100) & (data['id'] <= 200), ['postal', 'web']] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nL3RCWF-uHPE"},"source":["A lambda function that yields True/False values can also be used. Let's use it to select rows where the company name has 4 words in it:"]},{"cell_type":"code","metadata":{"id":"7VE7A8y5FRs1"},"source":["data.loc[data['company_name'].apply(lambda x: len(x.split(' ')) == 4)] "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPaTSTtIuHy5"},"source":["Selections can be achieved outside of the main `.loc` for clarity. First, form a separate variable with your selections:"]},{"cell_type":"code","metadata":{"id":"hoIb2jdwG7V_"},"source":["idx = data['company_name'].apply(lambda x: len(x.split(' ')) == 4)\n","idx"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XBsUKZejG8Kb"},"source":["Then, select only the True values in `idx` and only the 3 columns specified:"]},{"cell_type":"code","metadata":{"id":"o5oTIC3lHWgI"},"source":["data.loc[idx, ['email', 'first_name', 'company_name']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dedd0AH5IzRL"},"source":["# Pandas `apply`, `applymap` and `map`\n","\n","[Source](https://towardsdatascience.com/introduction-to-pandas-apply-applymap-and-map-5d3e044e93ff)"]},{"cell_type":"markdown","metadata":{"id":"OqTGafakI-pm"},"source":["Let's create a new Dataframe:"]},{"cell_type":"code","metadata":{"id":"Dg4f9ve4JCKS"},"source":["df = pd.DataFrame({\n","    'A': [1,2,3,4], \n","    'B': [10,20,30,40],\n","    'C': [20,40,60,80]\n","    }, \n","    index=['Row 1', 'Row 2', 'Row 3', 'Row 4'])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cme_rp_HKOgH"},"source":["## Using Apply\n","\n","The Pandas apply() is used to apply a function along an axis of the DataFrame or on values of Series.\n","\n","Let’s begin with a simple example, to sum each row and save the result to a new column \"D\":"]},{"cell_type":"code","metadata":{"id":"ALaNaJolJh7O"},"source":["def custom_sum(row):\n","    return row.sum()\n","    \n","df['D'] = df.apply(custom_sum, axis=1)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6fs4c57KnWe"},"source":["Do you really understand what just happened?\n","\n","Let’s take a look `df.apply(custom_sum, axis=1)`\n","\n","- The first parameter custom_sum is a function.\n","- The second parameter axis is to specify which axis the function is applied to. `0` for applying the function to each column and `1` for applying the function to each row.\n","\n","Let me explain this process in a more intuitive way. The second parameter `axis = 1` tells Pandas to use the row. So, the custom_sum is applied to each row and returns a new Series with the output of each row as value."]},{"cell_type":"markdown","metadata":{"id":"WOKqb6OaLNPQ"},"source":["With the understanding of the sum of each row, the sum of each column is just to use axis = 0 instead, first clearing out what we just did:"]},{"cell_type":"code","metadata":{"id":"gPPP03FXLReo"},"source":["df.drop('D', axis=1, inplace=True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hvncVyELv30"},"source":["df.loc['Row 5'] = df.apply(custom_sum, axis=0)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaKuhFF7L6Hs"},"source":["So far, we have been talking about `apply()` on a DataFrame. Similarly, `apply()` can be used on the values of Series. For example, multiply the column **C** by 2 and save the result to a new column **D**:"]},{"cell_type":"code","metadata":{"id":"qim8-LA1MT4v"},"source":["df.drop('Row 5', inplace=True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgrzYV8lMOmQ"},"source":["def multiply_by_2(val):\n","    return val * 2\n","\n","df['D'] = df['C'].apply(multiply_by_2)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_gZKZC7MO0w"},"source":["Notice that `df['C']` is used to select the column **C** and then call `apply()` with the only parameter `multiply_by_2`. We don’t need to specify axis anymore because Series is a one-dimensional array. The return value is a Series and get assigned to the new column **D** by `df[‘D’]`."]},{"cell_type":"markdown","metadata":{"id":"oBfcntmMNDTO"},"source":["Now, we could do exactly the same for the rows:"]},{"cell_type":"code","metadata":{"id":"0XnC4ExSNIj4"},"source":["df.drop('D', axis=1, inplace=True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eq6IAMoJNLhD"},"source":["df.loc['Row 5'] = df.loc['Row 4'].apply(multiply_by_2)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RddC1jZIREsC"},"source":["### Using labmdas\n","\n","As we saw in class, you can use Pandas `apply()` function with Labmdas.\n","\n","The lambda equivalent for the sum of each row of a DataFrame that we used above is:\n"]},{"cell_type":"code","metadata":{"id":"Kg3CRaxGRV-k"},"source":["df['D'] = df.apply(lambda x:x.sum(), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70mMfzfaRXsd"},"source":["Or, the lambda equivalent for the sum of each column of a DataFrame:\n"]},{"cell_type":"code","metadata":{"id":"3L86OdrvRpU8"},"source":["df['Row 5'] = df.apply(lambda x:x.sum(), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KxJZKEIhRq96"},"source":["And finally, the lambda equivalent for multiply by 2 on a Series:"]},{"cell_type":"code","metadata":{"id":"dRJwhZN4Rvjo"},"source":["df['D'] = df['C'].apply(lambda x:x*2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vw9z24mbRxAA"},"source":["### Using the `result_type` parameter\n","`result_type` is a parameter in apply() set to `expand`, `reduce`, or `broadcast` to get the desired type of result.\n","\n","In what we've done previously, if result_type is set to `broadcast` then the output will be a DataFrame substituted by the custom_sum value:\n"]},{"cell_type":"code","metadata":{"id":"bsMf28_gSDvR"},"source":["df.apply(custom_sum, axis=1, result_type='broadcast')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1t-7UuwJSLlU"},"source":["You can see that the result is broadcasted to the original shape of the frame, while the original index and columns are retained.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"srTxGU1zSVdX"},"source":["To understand `result_type`'s `expand` and `reduce`, you will first create a function that returns a list:"]},{"cell_type":"code","metadata":{"id":"9hMXbEHISPCF"},"source":["def cal_multi_col(row):\n","    return [row['A'] * 2, row['B'] * 3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hsIULPRSeih"},"source":["Let's apply this function on the dataframe's columns axis with result_type set as `expand`:"]},{"cell_type":"code","metadata":{"id":"qI6YecrkSrwY"},"source":["df.apply(cal_multi_col, axis=1, result_type='expand')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ATBiI4CnStHE"},"source":["The output is a new DataFrame with column names 0 and 1.\n","\n","To append this to the existing DataFrame, the result needs to be stored in a variable so the column names can be accessed by `resul.columns`:\n"]},{"cell_type":"code","metadata":{"id":"x-A1JMg0Sw1Q"},"source":["resul = df.apply(cal_multi_col, axis=1, result_type='expand')\n","df[resul.columns] = res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8u10YdYcTFLn"},"source":["Finally, apply the function across axis 1 with `result_type=reduce` . This is just the opposite of `expand` and returns a Series if possible rather than expanding list-like results:\n"]},{"cell_type":"code","metadata":{"id":"hNcJhaNvTLrr"},"source":["df['New'] = df.apply(cal_multi_col, axis=1, result_type='reduce')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grhJKf2mThDl"},"source":["## Using `applymap()`"]},{"cell_type":"markdown","metadata":{"id":"YFmca45tTn_m"},"source":["`applymap()` is used for element-wise operation across the whole DataFrame. It's an optimized method and in some particular cases it works much faster than `apply()` (but it’s always good to compare it with `apply()` for big operations).\n","\n","Our example too output a DataFrame with number squared from before, with applymap would be:"]},{"cell_type":"code","metadata":{"id":"D-WRj-j5UU2V"},"source":["df.applymap(np.square)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ShkXX3XlTw96"},"source":["## Using `map()`"]},{"cell_type":"markdown","metadata":{"id":"PgXH5w-rT383"},"source":["`map()` is only available in Series and used for substituting each value in a Series with a new one.\n","\n","To get how the map() works, let's create a Series:"]},{"cell_type":"code","metadata":{"id":"K1HciOxfUhsb"},"source":["s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n","s"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6ZKJZi2Uq8E"},"source":["`map()` accepts a dict or a Series as input. Values that are not found in the dict are converted to `NaN`, unless the dict has a default value (as is the case of `defaultdict`):"]},{"cell_type":"code","metadata":{"id":"6bTH6D4vUvMu"},"source":["s.map({'cat': 'kitten', 'dog': 'puppy'})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWcFngr9U53E"},"source":["`map()` also accepts a function as input:"]},{"cell_type":"code","metadata":{"id":"pNoIQQtdVBnf"},"source":["s.map('I am a {}'.format)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SPZAn8EVVEHL"},"source":["If you want to avoid applying the function to missing values (and therefore dragging `NaN` down your processing), you can use `na_action='ignore'`:"]},{"cell_type":"code","metadata":{"id":"ohv2UxzXVVmW"},"source":["s.map('I am a {}'.format, na_action='ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3g37LswhWg8a"},"source":["# Filling up missing Data\n","\n","[Source](https://www.geeksforgeeks.org/python-pandas-dataframe-fillna-to-replace-null-values-in-dataframe/)\n","\n","Sometimes our data has null values, which are later displayed as `NaN` in Data Frame. Just like pandas `dropna()` method manages and removes `Null` values from a data frame, `fillna()` manages and let the user replace `NaN` values with some value of their own.\n","\n","[See the syntax in the Pandas Official Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"]},{"cell_type":"markdown","metadata":{"id":"qQE-HtHQXkGV"},"source":["## Replacing NaN values with a static value"]},{"cell_type":"code","metadata":{"id":"VamqHKNFP96i"},"source":["!wget https://bit.ly/ks-pds-csv5 -O {files_loc}/nba.csv\n","contents = !ls {files_loc}/*nba*\n","nba_file = contents[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0q9lbRkGLb5"},"source":["nba = pd.read_csv(os.path.join(nba_file))\n","nba"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hUOuAZ7RGsy-"},"source":["Here, all the null values in College column are going to be replaced with “No college” string. Firstly, the data frame is imported from CSV and then College column is selected and fillna() method is used on it:"]},{"cell_type":"code","metadata":{"id":"izTt3IlhG3aR"},"source":["nba.fillna({'College':'No College'})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-vKm4OJoQiH"},"source":["Working in place in the dataframe can be expressed somewhat differently as well:"]},{"cell_type":"code","metadata":{"id":"by1_CJ_ioGmc"},"source":["nba['College'].fillna('No College', inplace=True)\n","nba"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36UYovc8pDBn"},"source":["But look at what happens if we use the last syntax and we do not modify in place:"]},{"cell_type":"code","metadata":{"id":"HFnweFImpI0M"},"source":["nba = pd.read_csv(os.path.join(files_loc, \"nba.csv\")) # Rereading, we modified nba df before\n","nba_1 = nba['College'].fillna('No College')\n","nba_1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3Vvos74qn5o"},"source":["type(nba['College'].fillna('No College'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojOkJycyqzKt"},"source":["type(nba['College'].fillna('No College', inplace=True))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfN4Umomlnex"},"source":["## Using the `method` parameter\n","Now, let's set the `method` to `ffill` (forward fill) and hence the value in the same column replaces the null value. In this case 'Georgia State' replaced 'null' value in college column of row 4 and 5.\n","\n","Similarly, bfill, backfill and pad methods can also be used:"]},{"cell_type":"code","metadata":{"id":"_7ja5fapt_a5"},"source":["nba = pd.read_csv(os.path.join(files_loc, \"nba.csv\")) # Reloading, we modified nba df before\n","nba['College'].fillna(method='ffill', inplace=True)\n","nba"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"voN5CLczuSqu"},"source":["And now, let's do the same but not modifying the nba original dataframe. This is going to involve creating a new series the way we want it and using the [`assign`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html) method on the original dataframe that returns a copy with the desired modifications:"]},{"cell_type":"code","metadata":{"id":"izegsLFtl19D"},"source":["nba = pd.read_csv(os.path.join(files_loc, \"nba.csv\")) # Reloading, we modified nba df before\n","new_college = nba['College'].fillna(method='ffill')\n","nba_2 = nba.assign(College=new_college)\n","nba_2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9onDJ-AIt9fH"},"source":["nba"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C_UVnS6SmHKU"},"source":["## Using `limit`\n","Let's set a limit of 1 is set in the fillna() method to check if the function stops replacing after one successful replacement of NaN value or not:"]},{"cell_type":"code","metadata":{"id":"oVu0Cj2Imd3i"},"source":["nba['College'].fillna(method='ffill', limit=1, inplace=True)\n","nba"],"execution_count":null,"outputs":[]}]}